{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYdJsskaZrTF"
      },
      "source": [
        "# Vector & Graph Retrieval Augmented Generation\n",
        "\n",
        "In this notebook we will be using the LLama Index toolkit to store and retrieve our dataset that will be used as input into our LLM Use case. The goal here is to demonstrate how we can enhance a standard LLM to answer use case specific questions with high accuracy\n",
        "\n",
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1YLaWMCZrTM"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index==0.9.43"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhJv6Fjdai76",
        "outputId": "b6e66855-a712-41e9-d0f8-e26040b328ec"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index==0.9.43\n",
            "  Downloading llama_index-0.9.43-py3-none-any.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.9.43) (2.0.25)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.9.43) (3.9.3)\n",
            "Collecting dataclasses-json (from llama-index==0.9.43)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index==0.9.43)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index==0.9.43)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.9.43) (2023.6.0)\n",
            "Collecting httpx (from llama-index==0.9.43)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.9.43) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.9.43) (3.2.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.9.43) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index==0.9.43) (1.25.2)\n",
            "Collecting openai>=1.1.0 (from llama-index==0.9.43)\n",
            "  Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index==0.9.43) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.9.43) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.9.43) (8.2.3)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index==0.9.43)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.9.43) (4.9.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index==0.9.43)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index==0.9.43) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index==0.9.43) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index==0.9.43) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index==0.9.43) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index==0.9.43) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index==0.9.43) (4.0.3)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama-index==0.9.43) (1.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index==0.9.43) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index==0.9.43) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index==0.9.43) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index==0.9.43) (4.66.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index==0.9.43) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index==0.9.43) (1.7.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index==0.9.43) (2.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index==0.9.43) (1.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index==0.9.43) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx->llama-index==0.9.43)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index==0.9.43) (3.6)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index==0.9.43)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index==0.9.43) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index==0.9.43) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index==0.9.43) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index==0.9.43)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index==0.9.43)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index==0.9.43) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index==0.9.43) (2023.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index==0.9.43) (1.2.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index==0.9.43) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index==0.9.43) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index==0.9.43) (2.16.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index==0.9.43) (1.16.0)\n",
            "Installing collected packages: dirtyjson, mypy-extensions, marshmallow, h11, deprecated, typing-inspect, tiktoken, httpcore, httpx, dataclasses-json, openai, llama-index\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.4 deprecated-1.2.14 dirtyjson-1.0.8 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 llama-index-0.9.43 marshmallow-3.20.2 mypy-extensions-1.0.0 openai-1.12.0 tiktoken-0.6.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "m8DuOTvsZrTM"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pypdf pyvis llama_index==0.9.43"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Icf4vIcFaNW8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6gyM0kJFaRDv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ajtVoZrHZrTN"
      },
      "outputs": [],
      "source": [
        "# import the llama_\n",
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
        "from llama_index import ServiceContext\n",
        "from llama_index.storage.storage_context import StorageContext\n",
        "from llama_index.graph_stores import SimpleGraphStore\n",
        "from llama_index import KnowledgeGraphIndex\n",
        "from llama_index.llms import OpenAI\n",
        "from llama_index.embeddings import OpenAIEmbedding\n",
        "\n",
        "import pickle\n",
        "\n",
        "from pyvis.network import Network\n",
        "\n",
        "from ipywidgets import GridspecLayout\n",
        "import ipywidgets as widgets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecQ3Dp4yZrTO"
      },
      "source": [
        "## API Key Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vzB92AcSZrTO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0a4eb14-92a0-474b-dfb1-2640afc55cad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:llama_index.service_context:chunk_size_limit is deprecated, please specify chunk_size instead\n"
          ]
        }
      ],
      "source": [
        "OPENAI_API_KEY = \"tomoro_jpmc_event_2024\"\n",
        "\n",
        "\n",
        "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo\",api_base='https://jpmcproxy-j2v7yxjplq-nw.a.run.app/v1', api_key='tomoro_jpmc_event_2024')\n",
        "embeds = OpenAIEmbedding(api_base='https://jpmcproxy-j2v7yxjplq-nw.a.run.app/v1', api_key=OPENAI_API_KEY)\n",
        "service_context = ServiceContext.from_defaults(llm=llm, chunk_size_limit=512,embed_model=embeds)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHGQc79sZrTO"
      },
      "source": [
        "The documents we are querying are related to BABA, AliBaba , recent articles from Seeking Alpha as well as earnings call transcript."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kIRL6tH9ZrTO"
      },
      "outputs": [],
      "source": [
        "document_folder = './documents/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc11Je_iZrTP"
      },
      "source": [
        "### First a simple example implementing RAG via Vector Embeddings:\n",
        "\n",
        "This code allows us to query the documents, retrieve relevant content from the documents with respect to the question, then this will be sent to the LLM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MuO6IEHGZrTP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cd1a38c-7e5f-47f9-f5a4-1d5b19946046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is the model output: Alibaba is facing challenges in its business. The company's earnings have not been growing as expected, and it has suffered impairments in some of its ventures. Competition is increasing, both domestically and internationally, which is impacting Alibaba's market share. The company is trying to strengthen its position by investing more in its international activities, but investors have doubts about whether these expenses will justify the results. Additionally, concerns have been raised in Europe regarding the influx of Chinese small-ticket items, which are seen as unfair competition for European manufacturers. Overall, Alibaba's Cloud and Chinese e-commerce businesses have lost market share, and it remains uncertain if this trend can be reversed or if it will accelerate further.\n"
          ]
        }
      ],
      "source": [
        "#Load the directory into LLamas directory reader\n",
        "documents = SimpleDirectoryReader(document_folder).load_data()\n",
        "\n",
        "#Index the documents\n",
        "simple_rag_index = VectorStoreIndex.from_documents(documents,service_context=service_context)\n",
        "\n",
        "#Set your query engine\n",
        "rag_query_engine = simple_rag_index.as_query_engine()\n",
        "\n",
        "\n",
        "#Pass your question against the vector store to receive the relevant context and pass to the LLM\n",
        "response = rag_query_engine.query(\"How are Alibaba doing?\")\n",
        "\n",
        "print(f\"Here is the model output: {response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAOM0YSPZrTP"
      },
      "source": [
        "### Example implementing RAG via Knowledge Graph:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iCQ4-4cZrTP"
      },
      "outputs": [],
      "source": [
        "graph_store = SimpleGraphStore()\n",
        "storage_context = StorageContext.from_defaults(graph_store=graph_store)\n",
        "\n",
        "kg_index = KnowledgeGraphIndex.from_documents(documents=documents,storage_context=storage_context,service_context=service_context)\n",
        "kg_query_engine = kg_index.as_query_engine()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgUhLr92ZrTP"
      },
      "source": [
        "Save the knowledge graph index as a file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxBI3vMWZrTQ"
      },
      "outputs": [],
      "source": [
        "with open('kg_index.pkl', 'wb') as f:\n",
        "    pickle.dump(kg_index, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTLI2s5AZrTQ"
      },
      "source": [
        "Use graphing tool called networkx https://networkx.org/documentation/stable/tutorial.html that supports graph building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7DXn9jEZrTQ"
      },
      "outputs": [],
      "source": [
        "g = kg_index.get_networkx_graph()\n",
        "net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
        "net.from_nx(g)\n",
        "net.show(\"AlibabaGraph.html\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOW6Dz5qZrTQ"
      },
      "source": [
        "Asking the same question using the knowledge graph to collect relevant information with respects to the question being asked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vds_Q5JvZrTQ"
      },
      "outputs": [],
      "source": [
        "response = kg_query_engine.query('What are the most divergent opinions on Alibaba?')\n",
        "print (response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gvsYy_eZrTR"
      },
      "outputs": [],
      "source": [
        "def rag_query(prompt):\n",
        "    return rag_query_engine.query(prompt)\n",
        "\n",
        "def kg_query(prompt):\n",
        "    return kg_query_engine.query(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v68IDbWkZrTR"
      },
      "source": [
        "This is a simple UI that allows you to ask questions with respects to the documents using both techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcbUVyZOZrTR"
      },
      "outputs": [],
      "source": [
        "grid = GridspecLayout(8,6)\n",
        "\n",
        "\n",
        "submit_button = widgets.Button(\n",
        "    description='Query',\n",
        "    disabled=False,\n",
        "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
        "    tooltip='Press to submit',\n",
        "    icon='lock',\n",
        "    layout=widgets.Layout(height='auto', width='auto'),\n",
        ")\n",
        "\n",
        "input_box = widgets.Textarea(\n",
        "    value=None,\n",
        "    placeholder='Type a question about your documents',\n",
        "    description='Question:',\n",
        "    disabled=False,\n",
        "    layout=widgets.Layout(height='auto', width='auto'),\n",
        "    rows=4\n",
        ")\n",
        "\n",
        "results_box = widgets.Textarea(\n",
        "    value=None,\n",
        "    placeholder='Results...',\n",
        "    description='Answer:',\n",
        "    disabled=False,\n",
        "    layout=widgets.Layout(height='auto', width='auto'),\n",
        "    rows=4\n",
        ")\n",
        "\n",
        "# we will populate this later with our list of methods.\n",
        "dropdown = widgets.Select(\n",
        "    options=['RAG','KG Rag'],\n",
        "    value='RAG',\n",
        "    # rows=10,\n",
        "    description='Method:',\n",
        "    disabled=False\n",
        ")\n",
        "filter_methods = {'RAG':rag_query,'KG Rag':kg_query}\n",
        "dropdown.options = (filter_methods.keys())\n",
        "\n",
        "grid[4:7,5] = dropdown\n",
        "grid[1:4,:5] = input_box\n",
        "grid[1:3,5] = submit_button\n",
        "grid[4:8,:5] = results_box\n",
        "\n",
        "# anywhere you can now just update the variable and it will live update.\n",
        "def question(e):\n",
        "    user_input = input_box.value\n",
        "    method = filter_methods[dropdown.value]\n",
        "    results_box.value=method(user_input).response\n",
        "\n",
        "submit_button.on_click(question)\n",
        "\n",
        "grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_cK7518ZrTR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}